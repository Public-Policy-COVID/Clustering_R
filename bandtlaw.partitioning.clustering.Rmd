---
title: 'Clustering Analyses: Partitioning'
author: "Bryn Bandt-law"
date: "2/25/2021"
output:
  html_document: default
  pdf_document: default
---


The 'knit' chunck will  allow us to 'knit' the Rmarkdown to a pdf for submission

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo= TRUE)
```

**Clustering Technique: Partitioning**


read in Group 4 merged data set from out github folder

```{r}
library(readr)

link='https://raw.githubusercontent.com/Public-Policy-COVID/students_merge/main/Merged_data.csv'

data = read.csv(link)
```

reset indexes to R format:
```{r}
row.names(data)=NULL
```


**Partitioning**

-We will request a particular number of clusters to the algorithm. The algorithm will put every case in one of those clusters (note: outliers affect output)


For clustering, the variables need to be numeric. Change non-numeric variables (Deaths_COVID & Deaths_total) with integers to numeric.

```{r}
data$Deaths_COVID<-as.numeric(data$Deaths_COVID)

data$Deaths_total<-as.numeric(data$Deaths_total)
```

a. select variables to use for clustering
```{r}
dfClus=data[,c('Number_of_beds','mask_score','Deaths_COVID','Deaths_total','Number_of_hospitals', "black_total_pct","white_total_pct")]

summary(dfClus)
```

b. rescale units
```{r}
dfClus=scale(dfClus)
summary(dfClus)
```

c. rename subset indexes and  verify input:
```{r}

row.names(dfClus)=data$Location
head(dfClus)

```


d. set random seed for replicability of results
```{r}
set.seed(999) 

```


e. designate distance method and compute distance  matrix
```{r}

library(cluster)
dfClus_D=cluster::daisy(x=dfClus)

```

f. For the partitioning technique, we need to indicate the number of clusters required
```{r}
NumCluster=4
res.pam = pam(x=dfClus_D,
              k = NumCluster,
              cluster.only = F)
```

g.Append the  clustering results to the dataframe (data)
```{r}
data$pam=as.factor(res.pam$clustering)

```


h. query the data frame (we will create a table to see the number of counties per cluster and will look at King, County, WA)

```{r}
table(data$pam)  

data[data$Location=="King_WA",'pam'] 

```


**Evaluate results**

(a)create average sillohuetes
```{r}
library(factoextra)
fviz_silhouette(res.pam)

```
    - the average silhouette width is .23

(b) detect anomolies:
      -save individual silhouettes
     
```{r}
pamEval=data.frame(res.pam$silinfo$widths)
head(pamEval)
```
      -request negative silhouettes.
      A negative silhouettes indicates that the item
      is poorly clustered 

```{r}
pamEval[pamEval$sil_width<0,]
```



